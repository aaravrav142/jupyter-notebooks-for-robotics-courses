{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Robot motion\n",
    "\n",
    "A fundamental aspect of the development of mobile robots is the motion itself. This is not a trivial matter as it is one of the main sources of uncertainty and other constraints to the movement difficult its implementation.\n",
    "This particular lesson introduces the concept of a robot's pose and how we deal with it in a probabilistic context.\n",
    "\n",
    "The pose itself can take multiple forms depending on the problems context:\n",
    "\n",
    "- **2D location**: In a planar context we only need to a 2d vector $[x, y]^T$ to locate a robot against a point of reference, the origin $(0, 0).$\n",
    "- **2D pose**: In most cases involving mobile robots, the location alone is insufficient. We need an aditional paramater known as orientation or *bearing*. Therefore, a robot's pose is usually expressed as $[x, y, \\theta]^T$. *In the rest of the course, we mostly refer to this one.*\n",
    "- **3D pose**: Although we will only mentioned in passing, for robotics applications in the 3D space, *i.e.* UAV or drones, not only a third axis $z$ is added, but to handle the orientation in a 3D environment we need 3 components, *i.e.* roll, pitch and yaw. This course is centered around planar movile robots so we will not use this one, nevertheless most methods could be adapted to 3D environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# IMPORTS\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "from utils.DrawRobot import DrawRobot\n",
    "from utils.tcomp import tcomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pose composition\n",
    "\n",
    "Given an initial pose $p_1$ and a pose differential $\\Delta p$, *i.e.* how much the robot has moved during an interval of time, we compute the final pose $p$ using the **composition of poses** function:\n",
    "\n",
    "$$\n",
    "    p_1 = \n",
    "        \\begin{bmatrix}\n",
    "            x_1 \\\\ y_1 \\\\ \\theta_1\n",
    "        \\end{bmatrix},\n",
    "    \\Delta p = \n",
    "        \\begin{bmatrix}\n",
    "            \\Delta x \\\\ \\Delta y \\\\ \\Delta \\theta\n",
    "        \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\begin{equation}\n",
    "    p = \\begin{bmatrix}\n",
    "            x \\\\ y \\\\ \\theta\n",
    "        \\end{bmatrix}\n",
    "        = p_1 \\oplus \\Delta p\n",
    "        = \\begin{bmatrix}\n",
    "            x_1 + \\Delta x \\cos \\theta_1 - \\Delta y \\sin \\theta_1 \\\\ \n",
    "            y_1 + \\Delta x \\sin \\theta_1 - \\Delta y \\cos \\theta_1 \\\\\n",
    "            \\theta_1 + \\Delta \\theta\n",
    "          \\end{bmatrix}\n",
    "    \\end{equation}\n",
    "$$\n",
    "\n",
    "\n",
    "The differential $\\Delta p$, although we are using it as control in this exercise, normally is calculated given the robot's locomotion or sensed by the wheel encoders.\n",
    "\n",
    "**Assignment**\n",
    "\n",
    "Modify the main function in the next cell for the robot to describe a $8m \\times 8m$ square path as seen in the figure below.\n",
    "\n",
    "The robot starts in the bottom-left corner $(0, 0)$ and heads north in increments of $2 m$. Each 4 steps it will turn right.\n",
    "\n",
    "**Example**\n",
    "\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig3-1-1.png\" alt=\"\">\n",
    "  <figcaption>Fig. 1: Route of our robot.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Robot():\n",
    "    '''Mobile robot implementation\n",
    "    \n",
    "        Attr:\n",
    "            pose: Expected position of the robot\n",
    "    '''\n",
    "    def __init__(self, mean):\n",
    "        self.pose = mean\n",
    "\n",
    "    def step(self, u):\n",
    "        self.pose = tcomp(self.pose, u)\n",
    "    \n",
    "    def draw(self, fig, ax):\n",
    "        DrawRobot(fig, ax, self.pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(robot):\n",
    "    \n",
    "    # PARAMETERS\n",
    "    num_steps = 15 # Number of motions\n",
    "    turning = 4  # Number of steps for turning\n",
    "    u = np.vstack([2., 0., 0.]) # Action control (pose increment)\n",
    "    angle_inc = -np.pi/2 # Angle increment\n",
    "    \n",
    "    # MATPLOTLIB\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.ion()\n",
    "    plt.draw()\n",
    "    plt.xlim((-2, 10))\n",
    "    plt.ylim((-2, 10))\n",
    "    \n",
    "    plt.grid()\n",
    "    robot.draw(fig, ax)\n",
    "    \n",
    "    # MAIN LOOP\n",
    "    for step in range(1,num_steps+1):\n",
    "        \n",
    "        # Check if the robot has to move in straight line or also has to turn\n",
    "        if None:\n",
    "            u[2] = None\n",
    "        else:\n",
    "            u[2] = None\n",
    "                \n",
    "        robot.step(u)\n",
    "        \n",
    "        robot.draw(fig, ax)\n",
    "        fig.canvas.draw()\n",
    "        plt.pause(0.1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_pose = np.vstack([0., 0., np.pi/2])\n",
    "robot = Robot(initial_pose)\n",
    "main(robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.2 Considering noise\n",
    "\n",
    "In the previous case, the robot motion was error-free, this is overly optimistic as in a real use case the conditions of the environment are a huge source of uncertainty.\n",
    "\n",
    "Therefore, we have to transform the movement of the robot into a (multidimensional) gaussian distribution.\n",
    "\n",
    "- The mean is still the pose differential in the previous exercise.\n",
    "- The covariance is a $3 \\times 3$ matrix, which defines the amount of error at each step (time interval) \n",
    "\n",
    "**Assignment**\n",
    "\n",
    "Now, add a Gaussian noise to the motion. Along with the expected pose, draw the real pose of the robot(affected by noise), assuming the incremental motion is:\n",
    "\n",
    "$$\n",
    "    \\Delta p = N(\\Delta p_{given}, \\Sigma_{\\Delta p})\n",
    "    \\textit{ with } \n",
    "    \\Sigma_{\\Delta p}  =\n",
    "        \\begin{bmatrix}\n",
    "            0.04 & 0 & 0 \\\\\n",
    "            0 & 0.04 & 0 \\\\\n",
    "            0 & 0 & 0.01\n",
    "        \\end{bmatrix}\n",
    "    (\\text{ units in }m^2 \\text{ and } rad^2)\n",
    "$$\n",
    "\n",
    "Run the cell several times to see that the motion (and the path) is different each time. Try also with different values of the covariance matrix.\n",
    "\n",
    "Complete this new class that extends our previous Robot by adding some amount of noise to the movement.\n",
    "\n",
    "**Example**\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig3-1-2.png\" alt=\"\">\n",
    "  <figcaption>Fig. 2: Movement of our robot using pose compositions. <br/>\n",
    "      Containing the expected poses (in red) and the true pose <br/> affected by noise (in blue)</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyRobot(Robot):\n",
    "    \"\"\"Mobile robot implementation. It's motion has a set ammount of noise.\n",
    "    \n",
    "        Attr:\n",
    "            pose: Inherited from Robot\n",
    "            true_pose: Real robot pose, which has been affected by some ammount of noise.\n",
    "            covariance: Amount of error of each step.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean, covariance):\n",
    "        super().__init__(mean)\n",
    "        self.true_pose = mean\n",
    "        self.covariance = covariance\n",
    "        \n",
    "    def step(self, step_increment):\n",
    "        \"\"\"Computes a single step of our noisy robot.\n",
    "        \n",
    "            super().step(...) updates the expected pose (without noise)\n",
    "            Generate a noisy increment based on step_increment and self.covariance.\n",
    "            Then this noisy increment is applied to self.true_pose\n",
    "        \"\"\"\n",
    "        super().step(step_increment)\n",
    "        # TODO: Implement noisy movement\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def draw(self, fig, ax):\n",
    "        super().draw(fig, ax)\n",
    "        DrawRobot(fig, ax, self.true_pose, color='blue')\n",
    "\n",
    "# RUN\n",
    "\n",
    "initial_pose = np.vstack([0., 0., np.pi/2])\n",
    "cov = np.diag([0.0, 0.0, 0.012])  \n",
    "\n",
    "robot = NoisyRobot(initial_pose, cov)\n",
    "main(robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Movement of a robot using velocity commands\n",
    "\n",
    "In the remaining assignments related to robot motion we will describe two probabilistic motion models for planar movement. The *velocity motion model* and the *odometry motion model*, the former being the main topic of this assignment.\n",
    "\n",
    "The *velocity motion model* it is used mainly for motion planning, where the details of the robot's movement are of importance and odometry information is not available (it is computed after the movement).\n",
    "\n",
    "This motion model is characterized by the use of two velocities to control the robot's movement: *linear velocity* $v$ and *angular velocity* $w$. Therefore, during the following exercises, the movement commands will be of the form: $$u = \\begin{bmatrix} v \\\\ w \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "from numpy import random\n",
    "\n",
    "from utils.PlotEllipse import PlotEllipse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.1\n",
    "\n",
    "**Context**\n",
    "\n",
    "This motion model is characterized by the following equations:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "\n",
    "- If $w \\neq 0$:\n",
    "\n",
    "    $$\n",
    "        x_t = x_{t-1} + \n",
    "        \\begin{bmatrix}\n",
    "            -R \\sin \\theta_{t-1} + + R \\sin(\\theta_{t-1} + \\Delta \\theta) \\\\ \n",
    "            R \\cos \\theta_{t-1} - R \\cos(\\theta_{t-1} + \\Delta \\theta)\\\\\n",
    "            \\Delta \\theta\n",
    "        \\end{bmatrix}\n",
    "    $$\n",
    "\n",
    "- If $w = 0$:\n",
    "\n",
    "    $$\n",
    "        x_t = x_{t-1} + \n",
    "        \\begin{bmatrix}\n",
    "            \\cos \\theta_{t-1} \\\\ \\sin \\theta_{t-1} \\\\ 0\n",
    "        \\end{bmatrix}\n",
    "    $$\n",
    "    <td/>       \n",
    "    <td>\n",
    "        $$ \n",
    "        \\begin{aligned}\n",
    "        v &= w \\cdot R \\\\\n",
    "        \\Delta \\theta &= w \\cdot  \\partial t\n",
    "        \\end{aligned}\n",
    "        $$\n",
    "    <td/>\n",
    "  <tr/>\n",
    "<table/>\n",
    "    \n",
    "**Assignment**\n",
    "\n",
    "Modify the following `main()`, introducing an if-else statement that takes into account when the robot moves in an straight line ($w = 0$). At this point we don't take into account uncertainty in the system: neither from the initial pose (matrix $P_{3\\times3}$) nor the movement $(v, w)$ (matrix $Q_{2\\times2}$).\n",
    "\n",
    "**Example**\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig3-2-1.png\" alt=\"\">\n",
    "  <figcaption>Fig. 1: Route of our robot.</figcaption>\n",
    "</figure>\n",
    "\n",
    "**Auxiliary code**\n",
    "\n",
    "To simplify the demo we'll provide the following auxuliary code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_pose(x, u, dt, cov=None):\n",
    "    ''' This function takes pose x and transform it according to the motion u=[v,w]'\n",
    "        applying the differential drive model.\n",
    "\n",
    "        Args:\n",
    "            x: current pose\n",
    "            u: differential command as a vector [v, w]'\n",
    "            dt: Time interval in which the movement occurs\n",
    "            cov: covariance of our movement. If not None, then add gaussian noise\n",
    "    '''\n",
    "    if cov is not None:\n",
    "        u += cov @ random.randn(2, 1)\n",
    "\n",
    "    if u[1] == 0: #linear motion w=0. Only motion in x\n",
    "        #dx = u(1)*dT; dy = 0; d_thetha = 0;\n",
    "        y = np.vstack([x[0] + u[0]*dt*np.cos(x[2]),\n",
    "                       x[1] + u[0]*dt*np.sin(x[2]),\n",
    "                       x[2]])\n",
    "    else: #Non-linear motion w=!0\n",
    "        R = u[0]/u[1] #v/w=r is the curvature radius\n",
    "        y = np.vstack([x[0] - R*np.sin(x[2]) + R*np.sin(x[2]+u[1]*dt),\n",
    "                       x[1] + R*np.cos(x[2]) - R*np.cos(x[2]+u[1]*dt),\n",
    "                       x[2] + u[1]*dt])\n",
    "\n",
    "    return y\n",
    "\n",
    "class VelocityRobot(object):\n",
    "    \"\"\" Mobile robot implementation that uses velocity commands.\n",
    "    \n",
    "        Attr:\n",
    "            pose: expected pose of the robot in the real world (without taking account noise)\n",
    "            dt: Duration of each step in seconds\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mean, dt):\n",
    "        self.pose = mean\n",
    "        self.dt = dt\n",
    "    def step(self, u):\n",
    "        self.pose = next_pose(self.pose, u, self.dt)\n",
    "    def draw(self, fig, ax):\n",
    "        DrawRobot(fig, ax, self.pose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the movement of your robot using the demo below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(robot, nSteps):\n",
    "          \n",
    "    v = 1 # Linear Velocity \n",
    "    l = 0.5 #Half the width of the robot\n",
    "        \n",
    "    # MATPLOTLIB\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.ion()\n",
    "    fig.canvas.draw()\n",
    "    plt.xlim((-2, 20))\n",
    "    plt.ylim((-2, 30))\n",
    "    \n",
    "    plt.grid()\n",
    "        \n",
    "    # MAIN LOOP\n",
    "    for k in range(1, nSteps + 1):\n",
    "        #control is a wiggle with constant linear velocity\n",
    "        u = np.vstack((v, np.pi / 10 * np.sin(4 * np.pi * k/nSteps)))\n",
    "        \n",
    "        robot.step(u)   \n",
    "        \n",
    "        #draw occasionally\n",
    "        if (k-1)%20 == 0:\n",
    "            robot.draw(fig, ax)\n",
    "            fig.canvas.draw()\n",
    "            plt.pause(0.1)\n",
    "\n",
    "\n",
    "# RUN \n",
    "dT = 0.1 # time steps size\n",
    "pose = np.vstack([0., 0., 0.])\n",
    "\n",
    "robot = VelocityRobot(pose, dT)\n",
    "main(robot, nSteps=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2\n",
    "\n",
    "**Context**\n",
    "\n",
    "Now we will include uncertainty to the previous exercise, changing the behaviour of the robot class you have implemented.\n",
    "\n",
    "In contrast to the noisy robot in practice 3-1, we will use the equations of the velocity motion model and their respective Jacobians to keep track of how confident we are of the robot's pose (i.e. the robot's pose now is also a gaussian distribution).\n",
    "\n",
    "Therefore, we have to deal with 2 Gaussian dists.: the **pose** $(x, P)$ and the **movement command** $(u, Q)$, the latter being applied during an interval of time $\\partial t$.\n",
    "\n",
    "The covariance of this movement $(Q)$ is defined as seen below. It is constant throughout the execution of our code\n",
    "\n",
    "$$\n",
    "    Q = \\begin{bmatrix}\n",
    "            \\sigma_v^2 & 0 \\\\\n",
    "            0 &  \\sigma_w^2\n",
    "        \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Whereas, the pose's covariance $(P_t)$ has do be updated at every step of the execution. To achieve this you'll have to use:\n",
    "\n",
    "$$P_t = JacF_x \\cdot P_{t-1} \\cdot JacF_x^T + JacF_u \\cdot Q \\cdot JacF_u^T$$\n",
    " \n",
    "Where $JacF_x$ and $JacF_u$ are the jacobians of our motion model, given the pose $x$ and the action $u$.\n",
    "Derivate the ecuation of this jacobians and check them against the solution in the apendix of the slides.\n",
    "      \n",
    "**Assignment**\n",
    "      \n",
    "1. Complete the following code: calculating the covariance matrix $P_k$ and then draw them as ellipses.\n",
    " \n",
    "\n",
    " \n",
    "**Example**\n",
    " \n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig3-2-2.png\" alt=\"\">\n",
    "  <figcaption>Fig. 2: Movement of a robot using velocity commands. <br/> Representing the expected pose (in red), the true pose (as dots) <br/> and the confidence ellipse.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_covariance(x, P, Q, u, dt):\n",
    "    ''' Compute the covariance of a robot following the velocity motion model\n",
    "\n",
    "        Args:\n",
    "            x: current pose (before movement)\n",
    "            u: differential command as a vector [v, w]''\n",
    "            dt: Time interval in which the movement occurs\n",
    "            P: current covariance of the pose\n",
    "            Q: covariance of our movement.\n",
    "    '''\n",
    "    # Aliases\n",
    "    v = u[0, 0]\n",
    "    w = u[1, 0]\n",
    "\n",
    "    sx, cx = np.sin(x[2, 0]), np.cos(x[2, 0]) #sin and cos for the previous robot heading\n",
    "    si, ci = np.sin(u[1, 0]*dt), np.cos(u[1, 0]*dt) #sin and cos for the heading increment\n",
    "    R = u[0, 0]/u[1, 0] #v/w Curvature radius\n",
    "\n",
    "    if u[1, 0] == 0:  #linear motion w=0 --> R = infinite\n",
    "        #TODO JACOBIAN HERE\n",
    "        raise NotImplementedError\n",
    "        JacF_x = None\n",
    "        JacF_u = None\n",
    "    else: #Non-linear motion w=!0\n",
    "        # TODO JACOBIAN HERE\n",
    "        raise NotImplementedError\n",
    "        JacF_x = None\n",
    "        JacF_u = None\n",
    "    #prediction steps\n",
    "    return (JacF_x@P@JacF_x.T)+(JacF_u@Q@JacF_u.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Draw a mark in the poses corresponding to the ground-truth, which need to be randomly generated from the $Q$ matrix. Then test it using your previous `main()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyVelocityRobot(VelocityRobot):\n",
    "    \"\"\" Mobile robot implementation that uses velocity commands.\n",
    "       \n",
    "        Attr:\n",
    "            [...]: Inherited from VelocityRobot\n",
    "            true_pose: expected pose of the robot in the real world (noisy)\n",
    "            cov_pose: Covariance of the pose at each step\n",
    "            cov_move: Covariance of each movement. It is a constant\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mean, cov_pose, cov_move, dt):\n",
    "        super().__init__(mean, dt)\n",
    "        self.true_pose = mean\n",
    "        self.cov_pose = cov_pose\n",
    "        self.cov_move = cov_move\n",
    "        \n",
    "    def step(self, u):\n",
    "        self.cov_pose = next_covariance(self.pose, self.cov_pose, self.cov_move, u, self.dt)\n",
    "        \n",
    "        super().step(u)\n",
    "        self.true_pose = next_pose(self.true_pose, u, self.dt, cov=self.cov_move)\n",
    "        \n",
    "    def draw(self, fig, ax):\n",
    "        super().draw(fig, ax)\n",
    "        el = PlotEllipse(fig, ax, self.pose, self.cov_pose)\n",
    "        ax.plot(self.true_pose[0, 0], self.true_pose[1, 0], 'o', color=el[0].get_color())\n",
    "\n",
    "# RUN\n",
    "dT = 0.1 # time steps size\n",
    "\n",
    "SigmaV = 0.1 #Standard deviation of the linear velocity. \n",
    "SigmaW = 0.1 #Standard deviation of the angular velocity\n",
    "nSteps = 400 #Number of motions\n",
    "\n",
    "P = np.diag([0.2, 0.4, 0.]) #pose covariance matrix 3x3\n",
    "Q = np.diag([SigmaV**2, SigmaW**2]) #motion covariance matrix 2x2\n",
    "\n",
    "robot = NoisyVelocityRobot(np.vstack([0., 0., 0.]), P, Q, dT)\n",
    "main(robot, nSteps=nSteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Movement of a robot using odometry commands\n",
    "\n",
    "The *odometry motion model* is more suitable to keep track and estimate the robots pose in contrast to the *velocity model*. The reason being, most robot bases provide some form of *odometry information*, a measurement of how much the robot has moved in reality, whose greater precision makes it useful to keep track of the pose.\n",
    "\n",
    "Although technically it is a measurement rather than a control, we \n",
    "treat it as control to simplify the modeling. The odometry commands take the form of:\n",
    "\n",
    "$$\n",
    "    u_t = \\begin{bmatrix}\n",
    "            \\Delta x  \\\\\n",
    "            \\Delta y \\\\\n",
    "            \\Delta \\theta\n",
    "        \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We'll implement this motion model in both analytical and sample form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "from utils.pause import pause\n",
    "from utils.Jacobians import J1, J2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.1 Analytical form\n",
    "\n",
    "**Context**\n",
    "\n",
    "Just as we did in lesson 3.1, the analytic form of the odometry motion model uses the composition of poses to model the robot's movement, providing only a notion of how much the pose has changed, not how did it get there.\n",
    "\n",
    "$$\n",
    "    p_1 \\oplus \\Delta p\n",
    "    = \\begin{bmatrix}\n",
    "        x_1 + \\Delta x \\cos \\theta_1 - \\Delta y \\sin \\theta_1 \\\\ \n",
    "        y_1 + \\Delta x \\sin \\theta_1 - \\Delta y \\cos \\theta_1 \\\\\n",
    "        \\theta_1 + \\Delta \\theta\n",
    "      \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The crux of this assignment is to keep track of the covariance matrix of the pose $(P)$, using the Jacobians of this movement model.\n",
    "\n",
    "**Assignment**\n",
    "\n",
    "Similarly to the exercise 3.1, we'll move a robot along a 8-by-8 square (in meters), in increments of 2m.\n",
    "Just as the exercise 3.2.2, you'll need to draw the uncertainty of the pose(as an ellipse) and the ground-truth of the position(randomly generated).\n",
    "\n",
    "$$\n",
    "    \\Sigma_{\\Delta_p} = \\begin{bmatrix}\n",
    "        0.04 & 0 & 0 \\\\\n",
    "        0 & 0.04 & 0 \\\\\n",
    "        0 & 0 & 0.01\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Example**\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig3-3-1.png\" width=\"400\" alt=\"\">\n",
    "  <figcaption>Fig. 1: Movement of a robot using odometry commands. <br/> Representing the expected pose (in red), the true pose (as dots) <br/> and the confidence ellipse.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Robot():\n",
    "    \"\"\" Simulation of a robot base\n",
    "    \n",
    "        Attrs:\n",
    "            pose: Expected pose of the robot\n",
    "            P: Covariance of the current pose\n",
    "            true_pose: Real pose of the robot(affected by noise)\n",
    "            Q: Covariance of the movement\n",
    "    \"\"\"\n",
    "    def __init__(self, x, P, Q):\n",
    "        self.pose = x\n",
    "        self.P = P\n",
    "        self.true_pose = self.pose\n",
    "        self.Q = Q\n",
    "        \n",
    "    def step(self, u):\n",
    "        # TODO Update expected pose\n",
    "        self.pose = None\n",
    "        \n",
    "        # TODO Generate true pose \n",
    "        self.true_pose = None\n",
    "        \n",
    "        # TODO Update covariance\n",
    "        self.P = None\n",
    "        \n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def draw(self, fig, ax):\n",
    "        DrawRobot(fig, ax, self.pose)\n",
    "        el = PlotEllipse(fig, ax, self.pose, self.P)\n",
    "        ax.plot(self.true_pose[0, 0], self.true_pose[1, 0], 'o', color=el[0].get_color())\n",
    "    \n",
    "def demo1(robot):  \n",
    "    # MATPLOTLIB\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim([-3, 11])\n",
    "    ax.set_ylim([-3, 11])\n",
    "    plt.ion()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    # MOVEMENT PARAMETERS\n",
    "    nSteps = 15\n",
    "    ang = -np.pi/2 # angle to turn in corners\n",
    "    u = np.vstack((2., 0., 0.))\n",
    "    \n",
    "    # MAIN LOOP\n",
    "    for i in range(nSteps):\n",
    "        # change angle on corners\n",
    "        if i % 4 == 3:\n",
    "            u[2, 0] = ang\n",
    "\n",
    "        #Update positions\n",
    "        robot.step(u)\n",
    "\n",
    "        # Restore angle iff changed\n",
    "        if i % 4 == 3:\n",
    "            u[2, 0] = 0\n",
    "\n",
    "        # Draw every loop\n",
    "        robot.draw(fig, ax)\n",
    "        fig.canvas.draw()\n",
    "        plt.pause(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.vstack([0., 0., np.pi/2]) # pose inicial\n",
    "\n",
    "# Probabilistic parameters\n",
    "P = np.diag([0., 0., 0.])\n",
    "Q = np.diag([0.04, 0.04, 0.01])\n",
    "\n",
    "robot = Robot(x, P, Q)\n",
    "demo1(robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.2 Sample form\n",
    "\n",
    "**Context**\n",
    "\n",
    "The analytical form used above, although useful for the probabilistic algorithms we will cover in this course, does not work well for sampling algorithms such as particle filters.\n",
    "\n",
    "The reason being, if we generate random samples from the gaussian distributions generated in the previous exercise, we will find some poses that are not feasible to the non-holonomic movement of a robot, i.e. they do not correspond to a velocity command $(v, w)$ with noise.\n",
    "\n",
    "The following *sample form* is a more realistic way to generate samples of the pose. Now we model the movement of the robot as a sequence of actions: \n",
    "\n",
    "1. **Turn**: to face the destination point.\n",
    "2. **Advance**: to arrive at the destination.\n",
    "3. **Turn**: to get to the desired angle.\n",
    "\n",
    "This type of order is expressed as:\n",
    "\n",
    "$$\n",
    "    u_t = \\begin{bmatrix}\n",
    "            \\theta_1  \\\\\n",
    "            d \\\\\n",
    "            \\theta_2\n",
    "        \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "It can easily be generated from odometry poses $[\\hat x_t, \\hat y_t,\\hat \\theta_t]'$ and $[\\hat x_{t-1}, \\hat y_{t-1},\\hat \\theta_{t-1}]'$ given the following equations:\n",
    "\n",
    "$$\n",
    "    \\begin{equation}\n",
    "    \\theta_1 =atan2(\\hat y_t -\\hat y_{t-1}, \\hat x_t -\\hat x_{t-1})- \\hat \\theta_{t-1} \\\\\n",
    "    d = \\sqrt{(\\hat y_t -\\hat y_{t-1})^2 + (\\hat x_t -\\hat x_{t-1})^2} \\\\\n",
    "    \\theta_2  = \\hat{\\theta}_t - \\hat{\\theta}_{t-1} - \\theta_1\n",
    "    \\end{equation}\n",
    "$$\n",
    "\n",
    "**Assignment**\n",
    "\n",
    "1. Implement a function that, given the previously mentioned $[\\hat x_t, \\hat y_t,\\hat \\theta_t]'$ and $[\\hat x_{t-1}, \\hat y_{t-1},\\hat \\theta_{t-1}]'$ generates an order $u_t = [ \\theta_1, d , \\theta_2 ]'$\n",
    "\n",
    "  Expected output for the commented example:\n",
    "\n",
    "  ```\n",
    "  array([[-3.92699082],\n",
    "       [ 1.41421356],\n",
    "       [ 2.35619449]])\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_move(pose_now, pose_old):\n",
    "    # TODO Complete the function\n",
    "    raise NotImplementedError\n",
    "    \n",
    "# EXAMPLE\n",
    "#generate_move(np.vstack([0., 0., 0.]), np.vstack([1., 1., np.pi/2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using the resulting control action $u_t = [\\theta_1, d, \\theta_2]'$ we can model the noise of the action in the following way:\n",
    "\n",
    "  $$\n",
    "    \\begin{equation}\n",
    "        \\theta_1 = \\hat\\theta_1 + \\text{sample}\\left(\\alpha_0 \\hat\\theta_1^2 + \\alpha_1 \\hat d^2 \\right) \\\\\n",
    "        d = \\hat d + \\text{sample}\\left(\\alpha_2 \\hat d^2 + \\alpha_3 \\left(\\hat\\theta_1^2 + \\hat d^2 \\right) \\right) \\\\\n",
    "        \\theta_2 = \\hat\\theta_2 + \\text{sample}\\left(\\alpha_0 \\hat\\theta_2^2 + \\alpha_1 \\hat d^2\\right)\n",
    "    \\end{equation}\n",
    "  $$\n",
    "\n",
    "  Where $sample(b)$ generates a random value from a distribution $N(0, b)$. The vector $\\alpha = [\\alpha_0, \\dots, \\alpha_3]$, models the robot's noise.\n",
    "\n",
    "  The pose of the robot at the end of the movement is computed as follows:\n",
    "\n",
    "$$\n",
    "    \\begin{equation}\n",
    "        x_t = x_{t-1} + d \\cos\\left(\\theta_{t-1} + \\theta_1 \\right) \\\\\n",
    "        y_t = y_{t-1} + d \\sin\\left(\\theta_{t-1} + \\theta_1 \\right) \\\\\n",
    "        \\theta_t = \\theta_{t-1} +  \\theta_1 +  \\theta_2\n",
    "    \\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampledRobot(object):\n",
    "    def __init__(self, mean, a, n_samples):\n",
    "        self.pose = mean\n",
    "        self.a = a\n",
    "        self.samples = np.tile(mean, n_samples)\n",
    "        \n",
    "    def step(self, u):\n",
    "        # TODO Update pose\n",
    "        self.pose = None\n",
    "        \n",
    "        # TODO Generate new samples\n",
    "        self.samples = None\n",
    "        \n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def draw(self, fig, ax):\n",
    "        DrawRobot(fig, ax, self.pose)\n",
    "        ax.plot(self.samples[0, :], self.samples[1, :], '.')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the pose of the robot (without angle) as a cloud of particles (samples of possible points which the robot can be at). Use the variables in the code below. Play with different values of 'a'. To improve this visualization the robot will move in increments of $0.5$ and we are to plot the particles each 4 increments.\n",
    "\n",
    "**Example**\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig3-3-2.png\" width=\"400\" alt=\"\">\n",
    "  <figcaption>Fig. 1: Movement of a robot using odometry commands in sampling form. <br/> Representing the expected pose (in red) and the samples (as clouds of dots) </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo2(robot):\n",
    "    # PARAMETERS\n",
    "    inc = .5\n",
    "    show_each = 4\n",
    "    limit_iterations = 32\n",
    "    \n",
    "    # MATPLOTLIB\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlim([-3, 11])\n",
    "    ax.set_ylim([-3, 11])\n",
    "    plt.ion()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # MAIN LOOP\n",
    "    robot.draw(fig, ax)\n",
    "    inc_pose = np.vstack((0., inc, 0.))\n",
    "    \n",
    "    for i in range(limit_iterations):\n",
    "        if i == 16:\n",
    "            inc_pose[0, 0] = inc\n",
    "            inc_pose[1, 0] = 0\n",
    "            inc_pose[2, 0] = -np.pi/2\n",
    "            \n",
    "        u = generate_move(robot.pose+inc_pose, robot.pose)\n",
    "        \n",
    "        robot.step(u)\n",
    "        \n",
    "        if i == 16:\n",
    "            inc_pose[2, 0] = 0\n",
    " \n",
    "        if i % show_each == show_each-1:\n",
    "            robot.draw(fig, ax)\n",
    "            fig.canvas.draw()\n",
    "            plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_particles = 100\n",
    "a = np.array([.07, .07, .03, .05])\n",
    "x = np.vstack((0., 0., np.pi/2))\n",
    "\n",
    "robot = SampledRobot(x, a, n_particles)\n",
    "demo2(robot)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
