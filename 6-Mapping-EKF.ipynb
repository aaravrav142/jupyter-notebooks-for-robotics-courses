{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.1 Mapping EFK\n",
    "\n",
    "## Theoretical background\n",
    "\n",
    "In the previous lessons we have applied two algorithms: *Least Squares* and the *Extended Kalman Filter* to the Localization problem. Both algorithms can also be applied to the Mapping problem, with some minimal changes.\n",
    "\n",
    "In contrast to previous lessons, we do not have a perfect map of the environment, but we do have perfect knowledge of the robots pose. The absence of a perfect map of the environment is a common occurence in the field of mobile robots, some times no map is provided, or even if we had a map, it may contain wrong information.\n",
    "To simplify the problem we will assume the environment is unchanging, which is false in most of the useful applications.\n",
    "\n",
    "This lesson will be centered around the EKF algorithm and how it is applied to mapping. We will assume you already know how to implement this algorithm, focusing only in the main differences of implementation:\n",
    "\n",
    "**First**, we ought to consider the consider the *state*, which in this case is a **vector of landmarks**. This takes the form of:\n",
    "\n",
    "$$m = \\textit{xEst} = [x_0, y_0, \\underbrace{x_1, y_1}_{\\text{Position of}\\\\\\text{landmark 1}}, \\dots]^T$$\n",
    "\n",
    "As we can see, we do not consider the orientation of the landmarks, therefore if $n$ is the number of seen landmarks, $len(m) = 2n$.\n",
    "\n",
    "**Second**, we need the covariace matrix of the state, which we can deduce from how the observations are taken:\n",
    "\n",
    "- A range-bearing sensor generates a measurement with a covariance: $\\Sigma_{r\\theta} = \\begin{bmatrix} \\sigma^2_r & 0 \\\\ 0 & \\sigma^2_\\theta  \\end{bmatrix}$\n",
    "- The contents of a map need to be transformed to the world frame: $\\Sigma_{xy} = J \\Sigma_{r\\theta} J^T$. Just as we learned in Lesson 4. (Sensing).\n",
    "- Finally we need to combine the covariances to build the map's one.:\n",
    "\n",
    "  $$\n",
    "  \\begin{bmatrix}\n",
    "    [\\Sigma^0_{xy}]_{2 \\times 2} & \\cdots & 0_{2 \\times 2} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    0_{2 \\times 2} & \\cdots & [\\Sigma^n_{xy}]_{2 \\times 2}\n",
    "  \\end{bmatrix}_{2n \\times 2n}\n",
    "  $$\n",
    "  \n",
    "**Third**, we face an additional problem we did not have on the Location problem, this is we do not observe the whole set of landmarks each time, furthemore we do not know the amount of landmarks there exists. We need to add the landmarks once we see them for the first time.\n",
    "\n",
    "For your convenience, it is included here the slide illustrating how the algorithm performs once the sensor takes a measurement to a landmark.\n",
    "\n",
    "![](images/fig6-1-1.png)\n",
    "\n",
    "In this case we make the assumption that the **robot’s pose is known** (without uncertainty)\n",
    "and we want to estimate the pdf of the location of a number of landmarks that are\n",
    "present in the robot’s surroundings, utilizing for that a **noisy sensor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from scipy import linalg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.tcomp import tcomp\n",
    "from utils.AngleWrap import AngleWrap\n",
    "from utils.DrawRobot import DrawRobot\n",
    "from utils.PlotEllipse import PlotEllipse\n",
    "from utils.Jacobians import J2\n",
    "from utils.unit6.MapCanvas import MapCanvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Complete the code.\n",
    "\n",
    "The algorithm has gaps at some key places, so your first goal is to fill them with the appropriate code. For that, first review the code that is written and understand what is going on. Concretely, your mission is to implement the Jacobians computation, as well as some stuff related to the measurements.\n",
    "\n",
    "- Take a look at the class that will simulate our robot. It is similar to robots in previous practices as it can move and observe some landmarks. There is no uncertainty in its movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EFKMappingRobot():\n",
    "    def __init__(self, true_pose, sigma_r, sigma_theta, n_features):\n",
    "        # Robot description\n",
    "        self.true_pose = true_pose\n",
    "        self.Q = np.diag([sigma_r, sigma_theta])**2\n",
    "        \n",
    "        # Map -- Initially empty\n",
    "        self.xEst = np.empty((0, 0))\n",
    "        self.PEst = np.empty((0, 0))\n",
    "        self.QEst = 1.0*self.Q\n",
    "        \n",
    "        self.MappedFeatures = -1*np.ones((n_features,1), int)\n",
    "        \n",
    "    def step(self, u):\n",
    "        self.true_pose = tcomp(self.true_pose, u)\n",
    "        \n",
    "    def observe(self, idx, world, noisy=True):\n",
    "        \"\"\" Generate a observation of a feature in our world\n",
    "        \n",
    "            Args:\n",
    "                world: Complete map of all landmarks in the world\n",
    "                idx: Landmark to observe (index in world matrix)\n",
    "                noisy: Add noise to z, prorportional to self.Q\n",
    "                \n",
    "            Returns:\n",
    "                z: One range and bearing observation\n",
    "        \"\"\"\n",
    "        \n",
    "        z = np.empty((2, 1))\n",
    "        delta = world[:, [idx]] - self.true_pose[0:2, :]\n",
    "        \n",
    "        # Range\n",
    "        z[0, :] = np.sqrt(np.sum(delta**2))\n",
    "        # Bearing\n",
    "        z[1, :] = np.arctan2(delta[1, 0],delta[0, 0]) - self.true_pose[2, 0]\n",
    "        z[1, :] = AngleWrap(z[1, :])\n",
    "        \n",
    "        if noisy:\n",
    "            z = z + np.sqrt(self.Q)@random.rand(2,1)\n",
    "            \n",
    "        return z\n",
    "    \n",
    "    def get_random_observation(self, world, noisy=True):\n",
    "        iFeatures = world.shape[1]\n",
    "        iFeature = random.randint(iFeatures)\n",
    "        z = self.observe(iFeature, world, noisy)\n",
    "        return z, [iFeature]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to build the EFK algorithm we are going to need to calculate some jacobians. Complete the following functions using the formulas from the theory lessons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetObsJacs(xPred, xFeature):\n",
    "    \"\"\" Calculate the jacobian of the observation model.\n",
    "        \n",
    "        Needed to update a landmark we have already seen.\n",
    "        Hint. Similar to the one described in unit 5 (Localization)\n",
    "        \n",
    "        Args:\n",
    "            xPred: True pose of our robot.\n",
    "            xFeature: Estimated pose of a landmark in our map. World p.o.v in cartesian coordinates.\n",
    "                Does not contain an angle.\n",
    "        \n",
    "        Return:\n",
    "            2x2 matrix containing the corresponding jacobian.\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return jHxf\n",
    "\n",
    "def GetNewFeatureJacs(Xv, z):\n",
    "    \"\"\" Calculate the jacobian for transforming an observation to the world frame\n",
    "    \n",
    "        Args:\n",
    "            Xv: True pose of our robot\n",
    "            z: Observation of a landmark. In polar coordinates from the p.o.v. of our robot.\n",
    "        \n",
    "        Returns:\n",
    "            2x2 matrix containing the corresponding jacobian.\n",
    "    \"\"\"\n",
    "    #TODO\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    return jGz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The EFK algorithm is divided in 2 steps: prediction and update. Depending on whether our robot has seen this landmark before or not the algorithm beheaves differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EFKLocalization(robot: EFKMappingRobot, z, iFeature):\n",
    "    \"\"\" EFK algorithm for mapping\n",
    "        \n",
    "        Args:\n",
    "            robot: Robot base (contains state map: xEst, PEst)\n",
    "            z: Observation of a landmark\n",
    "            iFeature: Index of z in the world map\n",
    "    \n",
    "        Returns: Nothing. But it modifies the state in robot\n",
    "    \"\"\"\n",
    "    \n",
    "    # We assume that the map is static (the state transition model of\n",
    "    xPred = robot.xEst\n",
    "    PPred = robot.PEst\n",
    "\n",
    "    # Check if feature observed is in map\n",
    "    if robot.MappedFeatures[iFeature] > -1:\n",
    "        # Find out where it is in state vector\n",
    "        FeatureIndex = robot.MappedFeatures[iFeature[0], 0]\n",
    "        \n",
    "        # xFeature is the current estimation of the position of the\n",
    "        # landmard \"FeatureIndex\"\n",
    "        xFeature = xPred[FeatureIndex:FeatureIndex+2]\n",
    "        \n",
    "        # TODO Predicts the observation\n",
    "        zPred = None # Hint: use robot.observe function\n",
    "\n",
    "        # Get observation Jacobians\n",
    "        jHxf = GetObsJacs(robot.true_pose, xFeature)\n",
    "        \n",
    "        # Fill in state jacobian\n",
    "        # (the jacobian is zero except for the observed landmark)\n",
    "        jH = None\n",
    "        \n",
    "        #\n",
    "        # Kalman update\n",
    "        #\n",
    "\n",
    "        Innov = z-zPred # Innovation\n",
    "        Innov[1] = AngleWrap(Innov[1])\n",
    "        S = jH@PPred@jH.T + robot.QEst\n",
    "        K = PPred@jH.T@linalg.inv(S) # Gain\n",
    "        robot.xEst = xPred + K@Innov\n",
    "        robot.PEst = PPred - K@S@K.T\n",
    "\n",
    "        #ensure P remains symmetric\n",
    "        robot.PEst = 0.5*(robot.PEst+robot.PEst.T)\n",
    "        \n",
    "    else:\n",
    "        # This is a new feature, so add it to the map\n",
    "        nStates = xPred.size \n",
    "        \n",
    "        # The observation is in the local frame of the robot, it has to\n",
    "        # be translated to the global frame\n",
    "        xFeature = np.vstack([\n",
    "            z[0, 0]*np.cos(z[1, 0] + robot.true_pose[2, 0]),\n",
    "            z[0, 0]*np.sin(z[1, 0] + robot.true_pose[2, 0])\n",
    "        ])\n",
    "\n",
    "        #TODO\n",
    "        xFeature = None\n",
    "\n",
    "        # Add it to the current state\n",
    "        if nStates == 0:\n",
    "            robot.xEst = xFeature\n",
    "        else:\n",
    "            robot.xEst = np.vstack([robot.xEst, xFeature]) #Each new feature two new rows\n",
    "\n",
    "        # Compute the jacobian\n",
    "        jGz = GetNewFeatureJacs(robot.true_pose, z) #Dimension 2x2\n",
    "        if nStates != 0:\n",
    "            # note we don't use jacobian w.r.t vehicle since the pose doesn’t have uncertainty\n",
    "            M = np.vstack([  \n",
    "                    np.hstack([np.eye(nStates), np.zeros((nStates, 2))]),\n",
    "                    np.hstack([np.zeros((2, nStates)), jGz])\n",
    "                ])\n",
    "        else:\n",
    "            M = jGz\n",
    "            \n",
    "        robot.PEst = M@linalg.block_diag(robot.PEst, robot.QEst)@M.T\n",
    "\n",
    "        #This can also be done directly PEst = [PEst,zeros(nStates,2);\n",
    "                                                # zeros(2,nStates),\n",
    "                                                # jGz*QEst*jGz']\n",
    "\n",
    "        #remember this feature as being mapped: we store its ID for the state vector\n",
    "        robot.MappedFeatures[iFeature] = robot.xEst.size-2\n",
    "        #Always an odd number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take a look to the following demo and use it to test your implementation with the parameters given below. You are not meant to modify the `main()` at any point of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(robot,\n",
    "         Map,\n",
    "         nFeatures,\n",
    "         mode='non_stop',\n",
    "         logger=None,\n",
    "         nSteps=100, # Number of motions\n",
    "         turning= 40, # Number of motions before turning (square path)\n",
    "         print_each=2):\n",
    "    \n",
    "    %matplotlib notebook\n",
    "    if mode == 'step_by_step':\n",
    "        matplotlib.use('TkAgg')\n",
    "\n",
    "    # storing the number of times a features has been seen\n",
    "    # also store the handler to the graphical info shown\n",
    "    canvas = MapCanvas(nFeatures)\n",
    "    \n",
    "    canvas.ax.plot(Map[0, :], Map[1, :], 'g*')\n",
    "    hObsLine = canvas.ax.plot([0,0], [0,0], linestyle=':')\n",
    "    \n",
    "    # Control action\n",
    "    u = np.zeros((3, 1))\n",
    "    u[0] = (2.*MapSize/1.5)/turning\n",
    "    u[1] = 0.\n",
    "    \n",
    "    # Start the loop!\n",
    "    for k in range(nSteps):\n",
    "        #\n",
    "        # Move the robot\n",
    "        #\n",
    "        u[2]=0.\n",
    "        if k%turning == turning-1:\n",
    "            u[2] = np.pi/2\n",
    "        \n",
    "        robot.step(u) # Perfectly known robot pose\n",
    "        \n",
    "        z, iFeature = robot.get_random_observation(world=Map)\n",
    "        \n",
    "        # Update the \"observedtimes\" for the feature and plot the reading\n",
    "        canvas.increment_observed_times(iFeature)\n",
    "        canvas.PlotNumberOfReadings(robot.true_pose, iFeature, Map)\n",
    "        \n",
    "        EFKLocalization(robot, z, iFeature)\n",
    "        \n",
    "        # Log important values\n",
    "        if logger is not None:\n",
    "            logger.log(k, robot, Map)\n",
    "        \n",
    "        # Drawings\n",
    "        if k%print_each == print_each-1:\n",
    "            DrawRobot(canvas.fig, canvas.ax,robot.true_pose, 'r')#plot(xVehicleTrue(1),xVehicleTrue(2),'r*')\n",
    "            canvas.DoMapGraphics(robot) # Draw estimated poitns (in black) and ellipses\n",
    "            plt.axis([-MapSize-5, MapSize+5, -MapSize-5, MapSize+5]) # Set limits again\n",
    "            plt.draw()\n",
    "            \n",
    "            if mode == 'step_by_step':\n",
    "                plt.waitforbuttonpress(-1)\n",
    "            elif mode == 'visualize_process':\n",
    "                plt.pause(0.2)\n",
    "            elif mode == 'non_stop':\n",
    "                pass # non stop!\n",
    "\n",
    "    # Final drawings\n",
    "    %matplotlib inline\n",
    "    if logger is not None:\n",
    "        logger.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Consider that only 1 landmark exists.\n",
    "\n",
    "Set the variable nFeatures to 1. Execute the program and modify the `main()` to show the content of the vector of states `xEst` and the covariance matriz `Pest` each 5 iterations. What dimensions do they have?\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig6-1-2.png\" width=\"400\" alt=\"\">\n",
    "  <figcaption>\n",
    "      Fig. 1: Execution of the EKF algorithmn for mapping (only one landmark). <br/>\n",
    "      it shows the true pose (in red), <br/>\n",
    "      the real pose of the landmark (as a green star), <br/>\n",
    "      and the estimation from the EKF algorithm (pose and confidence ellipse).\n",
    "  </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode = 'step_by_step'\n",
    "mode = 'visualize_process'\n",
    "#mode = 'non_stop'\n",
    "\n",
    "# WORLD MAP\n",
    "# Num features/landmarks considered within the map\n",
    "nFeatures = 1\n",
    "# Generation of the map\n",
    "MapSize = 100\n",
    "Map = MapSize*random.rand(2,nFeatures)-MapSize/2\n",
    "\n",
    "# ROBOT\n",
    "# Covariances for our very bad&expensive sensor (in the system <d,theta>)\n",
    "Sigma_r = 8.0\n",
    "Sigma_theta = 7*np.pi/180\n",
    "# Initial robot pose\n",
    "xVehicleTrue = np.vstack([-MapSize/1.5, -MapSize/1.5, 0.]) # We know the exact robot pose at any moment\n",
    "\n",
    "robot = EFKMappingRobot(xVehicleTrue, Sigma_r, Sigma_theta, nFeatures)\n",
    "\n",
    "main(robot, Map ,nFeatures, mode=mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. - Repeat the last point employing 5 landmarks.\n",
    "\n",
    "Explain why and how the content of the variables `xEst` and `Pest` has change. Show also, each 5 iterations, the content of the jacobian of the observation (`jH`). What structure does the matrix of covariances have? Is there any kind of correlation among the observations of different landmarks?\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/fig6-1-3.png\" width=\"400\" alt=\"\">\n",
    "  <figcaption>\n",
    "      Fig. 2: Execution of the EKF algorithmn for mapping (multiple landmarks). <br/>\n",
    "      Same as in Fig 1., each landmark is accompanied by a number of times observed.\n",
    "  </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode = 'step_by_step'\n",
    "mode = 'visualize_process'\n",
    "#mode = 'non_stop'\n",
    "\n",
    "# WORLD MAP\n",
    "# Num features/landmarks considered within the map\n",
    "nFeatures = 5\n",
    "# Generation of the map\n",
    "MapSize = 100\n",
    "Map = MapSize*random.rand(2,nFeatures)-MapSize/2\n",
    "\n",
    "# ROBOT\n",
    "# Covariances for our very bad&expensive sensor (in the system <d,theta>)\n",
    "Sigma_r = 8.0\n",
    "Sigma_theta = 7*np.pi/180\n",
    "# Initial robot pose\n",
    "xVehicleTrue = np.vstack([-MapSize/1.5, -MapSize/1.5, 0.]) # We know the exact robot pose at any moment\n",
    "\n",
    "robot = EFKMappingRobot(xVehicleTrue, Sigma_r, Sigma_theta, nFeatures)\n",
    "\n",
    "main(robot, Map ,nFeatures, mode=mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Results of the mapping process. \n",
    "\n",
    "We want to visualize how well the EFK algoritm performs. In the demo, there is an input parameter called logger, which is meant to store some information each loop and plot it at the end.\n",
    "\n",
    "Implement the following class to store the determinant of the covariance matrix of each landmark and the error in the fitting along the algorithm iterations. Plot it for the case of 5 landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Logger():\n",
    "    \"\"\" Logs info about the covariance and error of a map.\n",
    "    \n",
    "        Attrs:\n",
    "            n_features: Number of features in the world.\n",
    "            log_error: Matrix to store the error in the fitting for each landmark.\n",
    "            log_det: Matrix to store the determinant of the covariance matrix for each landmark.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, n_steps, n_features):\n",
    "        \"\"\" Initializes each matrix to log the information\n",
    "        \n",
    "            Args:\n",
    "                n_steps: Maximum number of steps our robot will take.\n",
    "                n_features: Number of features in the world.\n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.log_error = np.empty((n_steps,n_features))\n",
    "        self.log_det = np.empty((n_steps,n_features))\n",
    "            \n",
    "    def log(self, k: int, robot: EFKMappingRobot, Map: np.ndarray):\n",
    "        \"\"\" Computes relevant info about the error and covariances.\n",
    "        \n",
    "            It is called once per loop in the demo.\n",
    "        \n",
    "            Args:\n",
    "                k: Number of iteration we are at. Range: [0, n_steps)\n",
    "                robot: \n",
    "                Map:\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def plot(self):\n",
    "        \"\"\" Plot all relevant figures. It is called at the end of the demo\"\"\"\n",
    "        fig1 , ax1 =plt.subplots(1, 1, sharex=True)\n",
    "        fig2 , ax2 =plt.subplots(1, 1, sharex=True)\n",
    "        fig2.tight_layout()\n",
    "        fig1.tight_layout()\n",
    "\n",
    "        df1 = pd.DataFrame(data= self.log_error, columns = ['Landmark {}'.format(i) for i in range(self.n_features)])\n",
    "        ax1.set_title('Error between map and est')\n",
    "        df1.plot(ax = ax1)\n",
    "        df2 = pd.DataFrame(data=np.log(self.log_det), columns=['Landmark {}'.format(i) for i in range(self.n_features)])\n",
    "        ax2.set_title('Det. of covar.')\n",
    "        df2.plot(ax = ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mode = 'step_by_step'\n",
    "mode = 'visualize_process'\n",
    "#mode = 'non_stop'\n",
    "\n",
    "# WORLD MAP\n",
    "# Num features/landmarks considered within the map\n",
    "nFeatures = 5\n",
    "# Generation of the map\n",
    "MapSize = 100\n",
    "Map = MapSize*random.rand(2,nFeatures)-MapSize/2\n",
    "\n",
    "# ROBOT\n",
    "# Covariances for our very bad&expensive sensor (in the system <d,theta>)\n",
    "Sigma_r = 8.0\n",
    "Sigma_theta = 7*np.pi/180\n",
    "# Initial robot pose\n",
    "xVehicleTrue = np.vstack([-MapSize/1.5, -MapSize/1.5, 0.]) # We know the exact robot pose at any moment\n",
    "\n",
    "robot = EFKMappingRobot(xVehicleTrue, Sigma_r, Sigma_theta, nFeatures)\n",
    "\n",
    "nSteps=100\n",
    "logger = Logger(n_features=nFeatures, n_steps=nSteps)\n",
    "\n",
    "main(robot,\n",
    "     Map,\n",
    "     nFeatures,\n",
    "     logger=logger,\n",
    "     mode='non_stop',\n",
    "     nSteps=nSteps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
